{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 222)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m222\u001b[0m\n\u001b[0;31m    cnt_fea=cnt_fea+1\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# pytorch-kaldi v.0.1                                      \n",
    "# Mirco Ravanelli, Titouan Parcollet\n",
    "# Mila, University of Montreal\n",
    "# October 2018\n",
    "##########################################################\n",
    "\n",
    "import kaldi_io\n",
    "import numpy as np\n",
    "import sys\n",
    "from scipy.ndimage.interpolation import shift\n",
    "import time\n",
    "\n",
    "def load_dataset(fea_scp,fea_opts,lab_folder,lab_opts,left,right, max_sequence_length, fea_only=False):\n",
    "\n",
    "    fea = { k:m for k,m in kaldi_io.read_mat_ark('ark:copy-feats scp:'+fea_scp+' ark:- |'+fea_opts) }\n",
    "\n",
    "    if not fea_only:\n",
    "        lab = { k:v for k,v in kaldi_io.read_vec_int_ark('gunzip -c '+lab_folder+'/ali*.gz | '+lab_opts+' '+lab_folder+'/final.mdl ark:- ark:-|')  if k in fea} # Note that I'm copying only the aligments of the loaded fea\n",
    "        fea = {k: v for k, v in fea.items() if k in lab} # This way I remove all the features without an aligment (see log file in alidir \"Did not Succeded\")\n",
    "\n",
    "    end_snt=0\n",
    "    end_index=[]\n",
    "    snt_name=[]\n",
    "    fea_conc=[]\n",
    "    lab_conc=[]\n",
    "    \n",
    "    tmp=0\n",
    "    for k in sorted(sorted(fea.keys()), key=lambda k: len(fea[k])):\n",
    "\n",
    "        #####\n",
    "        # If the sequence length is above the threshold, we split it with a minimal length max/4\n",
    "        # If max length = 500, then the split will start at 500 + (500/4) = 625. \n",
    "        # A seq of length 625 will be splitted in one of 500 and one of 125\n",
    "\n",
    "        \n",
    "        if(len(fea[k]) > max_sequence_length) and max_sequence_length>0:\n",
    "            fea_chunked = []\n",
    "            lab_chunked = []\n",
    "            for i in range((len(fea[k]) + max_sequence_length - 1) // max_sequence_length):\n",
    "                if(len(fea[k][i * max_sequence_length:]) > max_sequence_length + (max_sequence_length/4)):\n",
    "                    fea_chunked.append(fea[k][i * max_sequence_length:(i + 1) * max_sequence_length])\n",
    "                    if not fea_only:\n",
    "                        lab_chunked.append(lab[k][i * max_sequence_length:(i + 1) * max_sequence_length])\n",
    "                    else:\n",
    "                        lab_chunked.append(np.zeros((fea[k][i * max_sequence_length:(i + 1) * max_sequence_length].shape[0],)))\n",
    "                else:\n",
    "                    fea_chunked.append(fea[k][i * max_sequence_length:])\n",
    "                    \n",
    "                    if not fea_only:\n",
    "                        lab_chunked.append(lab[k][i * max_sequence_length:])\n",
    "                    else:\n",
    "                        lab_chunked.append(np.zeros((fea[k][i * max_sequence_length:].shape[0],)))\n",
    "                    break\n",
    "\n",
    "            for j in range(0, len(fea_chunked)):\n",
    "                fea_conc.append(fea_chunked[j])\n",
    "                lab_conc.append(lab_chunked[j])\n",
    "                snt_name.append(k+'_split'+str(j))\n",
    "\n",
    "        else:\n",
    "            fea_conc.append(fea[k])\n",
    "            \n",
    "            if not fea_only:\n",
    "                lab_conc.append(lab[k])\n",
    "            else:\n",
    "                lab_conc.append(np.zeros((fea[k].shape[0],)))\n",
    "            snt_name.append(k)\n",
    "\n",
    "        tmp+=1\n",
    "\n",
    "    fea_zipped = zip(fea_conc,lab_conc)\n",
    "    fea_sorted = sorted(fea_zipped, key=lambda x: x[0].shape[0])\n",
    "    fea_conc,lab_conc = zip(*fea_sorted)\n",
    "      \n",
    "    for entry in fea_conc:\n",
    "        end_snt=end_snt+entry.shape[0]\n",
    "        end_index.append(end_snt)\n",
    "\n",
    "    fea_conc=np.concatenate(fea_conc)\n",
    "    lab_conc=np.concatenate(lab_conc)\n",
    "\n",
    "    return [snt_name,fea_conc,lab_conc,np.asarray(end_index)] \n",
    "\n",
    "\n",
    "def context_window_old(fea,left,right):\n",
    "    N_row=fea.shape[0]\n",
    "    N_fea=fea.shape[1]\n",
    "    frames = np.empty((N_row-left-right, N_fea*(left+right+1)))\n",
    " \n",
    "    for frame_index in range(left,N_row-right):\n",
    "        right_context=fea[frame_index+1:frame_index+right+1].flatten() # right context\n",
    "        left_context=fea[frame_index-left:frame_index].flatten() # left context\n",
    "        current_frame=np.concatenate([left_context,fea[frame_index],right_context])\n",
    "        frames[frame_index-left]=current_frame\n",
    "    return frames\n",
    "\n",
    "def context_window(fea,left,right):\n",
    " \n",
    "    N_elem=fea.shape[0]\n",
    "    N_fea=fea.shape[1]\n",
    "    \n",
    "    fea_conc=np.empty([N_elem,N_fea*(left+right+1)])\n",
    "    \n",
    "    index_fea=0\n",
    "    for lag in range(-left,right+1):\n",
    "        fea_conc[:,index_fea:index_fea+fea.shape[1]]=np.roll(fea,lag,axis=0)\n",
    "        index_fea=index_fea+fea.shape[1]\n",
    "        \n",
    "    fea_conc=fea_conc[left:fea_conc.shape[0]-right]\n",
    "    \n",
    "    return fea_conc\n",
    "\n",
    "\n",
    "def load_chunk(fea_scp,fea_opts,lab_folder,lab_opts,left,right,max_sequence_length, fea_only=False):\n",
    "    # open the file\n",
    "    [data_name,data_set,data_lab,end_index]=load_dataset(fea_scp,fea_opts,lab_folder,lab_opts,left,right, max_sequence_length, fea_only)\n",
    "\n",
    "    # Context window\n",
    "    if left!=0 or right!=0:\n",
    "        data_set=context_window(data_set,left,right)\n",
    "\n",
    "    end_index=end_index-left\n",
    "    end_index[-1]=end_index[-1]-right\n",
    "\n",
    "    # mean and variance normalization\n",
    "    data_set=(data_set-np.mean(data_set,axis=0))/np.std(data_set,axis=0)\n",
    "\n",
    "    # Label processing\n",
    "    data_lab=data_lab-data_lab.min()\n",
    "    if right>0:\n",
    "        data_lab=data_lab[left:-right]\n",
    "    else:\n",
    "        data_lab=data_lab[left:]   \n",
    "  \n",
    "    data_set=np.column_stack((data_set, data_lab))\n",
    "\n",
    "    return [data_name,data_set,end_index]\n",
    "\n",
    "def load_counts(class_counts_file):\n",
    "    with open(class_counts_file) as f:\n",
    "        row = next(f).strip().strip('[]').strip()\n",
    "        counts = np.array([ np.float32(v) for v in row.split() ])\n",
    "    return counts \n",
    "\n",
    "def read_lab_fea(fea_dict,lab_dict,cw_left_max,cw_right_max,max_seq_length, fea_only=False):\n",
    "    \n",
    "    fea_index=0\n",
    "    cnt_fea=0\n",
    "\n",
    "    for fea in fea_dict.keys():\n",
    "        \n",
    "        # reading the features\n",
    "        fea_scp=fea_dict[fea][1]\n",
    "        fea_opts=fea_dict[fea][2]\n",
    "        cw_left=int(fea_dict[fea][3])\n",
    "        cw_right=int(fea_dict[fea][4])\n",
    "        \n",
    "        cnt_lab=0\n",
    "\n",
    "        # Production case, we don't have labels (lab_name = none)\n",
    "        if fea_only:\n",
    "            lab_dict.update({'lab_name':'none'})\n",
    "\n",
    "        for lab in lab_dict.keys():\n",
    "            \n",
    "            # Production case, we don't have labels (lab_name = none)\n",
    "            if fea_only:\n",
    "                lab_folder=None \n",
    "                lab_opts=None\n",
    "            else:\n",
    "                lab_folder=lab_dict[lab][1]\n",
    "                lab_opts=lab_dict[lab][2]\n",
    "                \n",
    "            [data_name_fea,data_set_fea,data_end_index_fea]=load_chunk(fea_scp,fea_opts,lab_folder,lab_opts,cw_left,cw_right,max_seq_length, fea_only)\n",
    "    \n",
    "            # making the same dimenion for all the features (compensating for different context windows)\n",
    "            labs_fea=data_set_fea[cw_left_max-cw_left:data_set_fea.shape[0]-(cw_right_max-cw_right),-1]\n",
    "            data_set_fea=data_set_fea[cw_left_max-cw_left:data_set_fea.shape[0]-(cw_right_max-cw_right),0:-1]\n",
    "            data_end_index_fea=data_end_index_fea-(cw_left_max-cw_left)\n",
    "            data_end_index_fea[-1]=data_end_index_fea[-1]-(cw_right_max-cw_right)\n",
    "    \n",
    "            \n",
    "            \n",
    "            if cnt_fea==0 and cnt_lab==0:\n",
    "                data_set=data_set_fea\n",
    "                labs=labs_fea\n",
    "                data_end_index=data_end_index_fea\n",
    "                data_end_index=data_end_index_fea\n",
    "                data_name=data_name_fea\n",
    "                \n",
    "                fea_dict[fea].append(fea_index)\n",
    "                fea_index=fea_index+data_set_fea.shape[1]\n",
    "                fea_dict[fea].append(fea_index)\n",
    "                fea_dict[fea].append(fea_dict[fea][6]-fea_dict[fea][5])\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                if cnt_fea==0:\n",
    "                    labs=np.column_stack((labs,labs_fea))\n",
    "                \n",
    "                if cnt_lab==0:\n",
    "                    data_set=np.column_stack((data_set,data_set_fea))\n",
    "                    fea_dict[fea].append(fea_index)\n",
    "                    fea_index=fea_index+data_set_fea.shape[1]\n",
    "                    fea_dict[fea].append(fea_index)\n",
    "                    fea_dict[fea].append(fea_dict[fea][6]-fea_dict[fea][5])\n",
    "                \n",
    "                \n",
    "                # Checks if lab_names are the same for all the features\n",
    "                if not(data_name==data_name_fea):\n",
    "                    sys.stderr.write('ERROR: different sentence ids are detected for the different features. Plase check again input feature lists\"\\n')\n",
    "                    sys.exit(0)\n",
    "                \n",
    "                # Checks if end indexes are the same for all the features\n",
    "                if not(data_end_index==data_end_index_fea).all():\n",
    "                    sys.stderr.write('ERROR end_index must be the same for all the sentences\"\\n')\n",
    "                    sys.exit(0)\n",
    "                    \n",
    "            cnt_lab=cnt_lab+1    \n",
    "        cnt_fea=cnt_fea+1\n",
    "        \n",
    "    cnt_lab=0\n",
    "    if not fea_only:\n",
    "        for lab in lab_dict.keys():\n",
    "            lab_dict[lab].append(data_set.shape[1]+cnt_lab)\n",
    "            cnt_lab=cnt_lab+1\n",
    "           \n",
    "    data_set=np.column_stack((data_set,labs))\n",
    "\n",
    "    return [data_name,data_set,data_end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
